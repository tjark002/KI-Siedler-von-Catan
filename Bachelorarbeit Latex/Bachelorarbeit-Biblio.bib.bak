% Encoding: windows-1252

@InProceedings{Bergsma2008,
  author  = {Bergsma, Maurice and Spronck, Pieter},
  title   = {Adaptive Spatial Reasoning for Turn-based Strategy Games.},
  year    = {2008},
  month   = {01},
  journal = {Bijdragen},
}

@InProceedings{Ruiz2007,
  author = {Antonio Carlos S{\'a}nchez-Ruiz and Pedro A. Gonz{\'a}lez-Calero},
  title  = {Game AI for a Turn-based Strategy Game with Plan Adaptation and Ontology-based retrieval},
  year   = {2007},
}

@InProceedings{Weber2009,
  author = {Weber, Ben and Mateas, Michael},
  title  = {Case-Based Reasoning for Build Order in Real-Time Strategy Games.},
  year   = {2009},
  month  = {01},
}

@InProceedings{Abraham2010,
  author    = {Aswin Thomas Abraham and Kevin McGee},
  title     = {{AI} for dynamic team-mate adaptation in games},
  booktitle = {Proceedings of the 2010 {IEEE} Conference on Computational Intelligence and Games},
  year      = {2010},
  month     = {aug},
  publisher = {{IEEE}},
  doi       = {10.1109/itw.2010.5593326},
}

@InProceedings{Togelius2010,
  author    = {Julian Togelius and Sergey Karakovskiy and Robin Baumgarten},
  title     = {The 2009 Mario {AI} Competition},
  booktitle = {{IEEE} Congress on Evolutionary Computation},
  year      = {2010},
  month     = {jul},
  publisher = {{IEEE}},
  doi       = {10.1109/cec.2010.5586133},
}

@Article{Laird2001,
  author    = {J.E. Laird},
  title     = {Using a computer game to develop advanced {AI}},
  journal   = {Computer},
  year      = {2001},
  volume    = {34},
  number    = {7},
  pages     = {70--75},
  month     = {jul},
  doi       = {10.1109/2.933506},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InCollection{Aha2005,
  author    = {David W. Aha and Matthew Molineaux and Marc Ponsen},
  title     = {Learning to Win: Case-Based Plan Selection in a Real-Time Strategy Game},
  booktitle = {Case-Based Reasoning Research and Development},
  publisher = {Springer Berlin Heidelberg},
  year      = {2005},
  pages     = {5--20},
  doi       = {10.1007/11536406_4},
}

@Article{Ontanon2013,
  author    = {Santiago Ontanon and Gabriel Synnaeve and Alberto Uriarte and Florian Richoux and David Churchill and Mike Preuss},
  title     = {A Survey of Real-Time Strategy Game {AI} Research and Competition in {StarCraft}},
  journal   = {{IEEE} Transactions on Computational Intelligence and {AI} in Games},
  year      = {2013},
  volume    = {5},
  number    = {4},
  pages     = {293--311},
  month     = {dec},
  doi       = {10.1109/tciaig.2013.2286295},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@InProceedings{Wender2008,
  author    = {Stefan Wender and Ian Watson},
  title     = {Using reinforcement learning for city site selection in the turn-based strategy game Civilization {IV}},
  booktitle = {2008 {IEEE} Symposium On Computational Intelligence and Games},
  year      = {2008},
  month     = {dec},
  publisher = {{IEEE}},
  doi       = {10.1109/cig.2008.5035664},
}

@TechReport{Davis1999,
  author      = {Ian Lane Davis},
  title       = {Strategies for Strategy Game AI},
  institution = {ActivisionI, Inc.},
  year        = {1999},
}

@InProceedings{Mayer2007,
  author    = {Helmut A. Mayer},
  title     = {Board Representations for Neural Go Players Learning by Temporal Difference},
  booktitle = {2007 {IEEE} Symposium on Computational Intelligence and Games},
  year      = {2007},
  month     = {apr},
  publisher = {{IEEE}},
  doi       = {10.1109/cig.2007.368096},
}

@Book{Puppe1996,
  title     = {Wissensbasierte Diagnose- und Informationssysteme},
  publisher = {Springer Berlin Heidelberg},
  year      = {1996},
  author    = {Frank Puppe and Stefan Bamberger and Ute Gappa and Karsten Poeck},
  doi       = {10.1007/978-3-642-61471-2},
}

@Misc{Althoff2019,
  author = {Prof. Dr. Klaus-Dieter Althoff},
  title  = {Vorlesung Wissensbasierte Systeme},
  month  = nov,
  year   = {2019},
}

@InProceedings{Zupan1994,
  author = {J. Zupan},
  title  = {Introduction to Artificial Neural Network (ANN) Methods: What They Are and How to Use Them*.},
  year   = {1994},
}

@MastersThesis{Hillmann2017,
  author = {Jannis Hillmann},
  title  = {Konzeption und Entwicklung eines Prototypen für ein lernfähiges Multi-Agenten-System mittels des fallbasierten Schließens im Szenario einer First-Person-Perspektive},
  school = {Universtiät Hildesheim},
  year   = {2017},
}

@Article{Nwankpa2018,
  author      = {Chigozie Nwankpa and Winifred Ijomah and Anthony Gachagan and Stephen Marshall},
  title       = {Activation Functions: Comparison of trends in Practice and Research for Deep Learning},
  year        = {2018},
  abstract    = {Deep neural networks have been successfully used in diverse emerging domains to solve real world complex problems with may more deep learning(DL) architectures, being developed to date. To achieve these state-of-the-art performances, the DL architectures use activation functions (AFs), to perform diverse computations between the hidden layers and the output layers of any given DL architecture. This paper presents a survey on the existing AFs used in deep learning applications and highlights the recent trends in the use of the activation functions for deep learning applications. The novelty of this paper is that it compiles majority of the AFs used in DL and outlines the current trends in the applications and usage of these functions in practical deep learning deployments against the state-of-the-art research results. This compilation will aid in making effective decisions in the choice of the most suitable and appropriate activation function for any given application, ready for deployment. This paper is timely because most research papers on AF highlights similar works and results while this paper will be the first, to compile the trends in AF applications in practice against the research results from literature, found in deep learning research to date.},
  date        = {2018-11-08},
  eprint      = {http://arxiv.org/abs/1811.03378v1},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1811.03378v1:PDF},
  keywords    = {cs.LG, cs.CV},
}

@Article{Ramachandran2017,
  author      = {Prajit Ramachandran and Barret Zoph and Quoc V. Le},
  title       = {Searching for Activation Functions},
  year        = {2017},
  abstract    = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, $f(x) = x \cdot \text{sigmoid}(\beta x)$, which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9\% for Mobile NASNet-A and 0.6\% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
  date        = {2017-10-16},
  eprint      = {http://arxiv.org/abs/1710.05941v2},
  eprintclass = {cs.NE},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1710.05941v2:PDF},
  keywords    = {cs.NE, cs.CV, cs.LG},
}

@InProceedings{Baraha2017,
  author    = {Satyakam Baraha and Pradyut Kumar Biswal},
  title     = {Implementation of activation functions for {ELM} based classifiers},
  booktitle = {2017 International Conference on Wireless Communications, Signal Processing and Networking ({WiSPNET})},
  year      = {2017},
  month     = {mar},
  publisher = {{IEEE}},
  doi       = {10.1109/wispnet.2017.8299920},
}

@Article{Agostinelli2014,
  author      = {Forest Agostinelli and Matthew Hoffman and Peter Sadowski and Pierre Baldi},
  title       = {Learning Activation Functions to Improve Deep Neural Networks},
  year        = {2014},
  abstract    = {Artificial neural networks typically have a fixed, non-linear activation function at each neuron. We have designed a novel form of piecewise linear activation function that is learned independently for each neuron using gradient descent. With this adaptive activation function, we are able to improve upon deep neural network architectures composed of static rectified linear units, achieving state-of-the-art performance on CIFAR-10 (7.51%), CIFAR-100 (30.83%), and a benchmark from high-energy physics involving Higgs boson decay modes.},
  date        = {2014-12-21},
  eprint      = {http://arxiv.org/abs/1412.6830v3},
  eprintclass = {cs.NE},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/1412.6830v3:PDF},
  keywords    = {cs.NE, cs.CV, cs.LG, stat.ML},
}

@Misc{Butt2016,
  author       = {John Butts},
  howpublished = {Github Repository},
  month        = oct,
  year         = {2016},
  timestamp    = {2020-09-17},
  url          = {https://github.com/buttsj/unity-settlers-of-catan},
}

@Comment{jabref-meta: databaseType:bibtex;}
